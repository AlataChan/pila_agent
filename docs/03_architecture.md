# 系统架构设计文档 (MVP)

## 1. 引言

本文档基于《公估报告智能撰写助手 - MVP 产品需求文档》(PRD_MVP.md) 中的规划，详细阐述了MVP版本的系统架构设计。目标是构建一个稳定、可扩展、易于维护的系统，以支持AI辅助公估报告撰写的核心功能。

## 2. 架构总览

系统采用前后端分离的微服务化思想（尽管MVP阶段服务数量较少），主要由前端应用、后端API服务、AI服务接口、OCR服务以及持久化存储等组件构成。

```mermaid
flowchart LR
  subgraph 用户浏览器/客户端
    A[用户界面 (React + Next.js)]
  end

  subgraph 后端服务 (部署于云服务器/容器)
    B(API网关/负载均衡器 - 可选，MVP初期可简化)
    C[核心业务API服务 (FastAPI)]
    D[AI服务接口 (FastAPI/Python)]
    E[OCR服务 (MarkItDown/云服务封装)]
    F[任务队列 (Celery + Redis/RabbitMQ - MVP初期可选同步)]
  end

  subgraph 持久化存储
    G[数据库 (PostgreSQL)]
    H[对象存储 (MinIO/S3)]
  end

  subgraph 第三方服务
    I[大语言模型 (LLM) API]
    J[外部OCR服务 (如调用云厂商API)]
  end

  A -->|HTTPS/REST API| B
  B --> C
  C -->|内部调用/消息队列| D
  C -->|内部调用/消息队列| E
  C -->|任务分发| F
  F --> D
  F --> E
  C --> G
  C --> H
  D -->|API调用| I
  E -->|API调用| J
```

## 3. 组件详细设计

### 3.1 前端应用 (User Interface)
*   **技术栈**: React, Next.js, TypeScript, TipTap (富文本编辑器)。
*   **主要职责**:
    *   提供用户友好的操作界面，包括文件上传、报告内容编辑、AI功能触发等。
    *   通过REST API与后端核心业务API服务进行交互。
    *   实现聊天式文件上传与状态反馈。
    *   集成TipTap编辑器，提供基础的富文本编辑功能。
    *   处理用户身份验证和会话管理。
    *   请求后端导出Word报告。
*   **部署**: 静态文件部署 (如Vercel, Netlify, 或通过Nginx服务)。

### 3.2 核心业务API服务 (Core Business API Service)
*   **技术栈**: Python, FastAPI。
*   **主要职责**:
    *   处理前端应用的所有业务请求。
    *   用户认证与授权管理。
    *   文件上传处理逻辑，调用对象存储服务保存文件。
    *   触发OCR任务：将文件信息发送给OCR服务或任务队列。
    *   报告草稿的创建、读取、更新、删除 (CRUD) 操作，与数据库交互。
    *   协调AI章节生成：接收前端请求，准备上下文数据和提示词，调用AI服务接口。
    *   报告导出逻辑：从数据库获取报告内容，调用报告渲染模块生成Word文档。
    *   管理与数据库、对象存储、任务队列、AI服务接口、OCR服务的通信。
*   **接口**: 提供符合OpenAPI规范的RESTful API。

### 3.3 AI服务接口 (AI Service Interface)
*   **技术栈**: Python, FastAPI (或其他适合LLM集成的框架)。
*   **主要职责**:
    *   封装对大语言模型 (LLM) API的调用逻辑。
    *   接收来自核心业务API服务的请求，包含特定章节的上下文数据和预设的提示词模板。
    *   根据任务类型（如生成“事故经过”、“保单摘要”），动态填充提示词模板。
    *   调用LLM API，获取生成的文本内容。
    *   对LLM的输出进行初步的格式化或错误处理（如果需要）。
    *   将生成的文本返回给核心业务API服务。
*   **设计考虑**: 
    *   应设计为无状态服务，便于水平扩展。
    *   考虑LLM API的调用成本和速率限制，可能需要实现重试、缓存（对于相同输入）等机制。
    *   提示词管理：可以考虑将提示词模板存储在配置文件或数据库中，方便迭代和管理。

### 3.4 OCR服务 (OCR Service)
*   **技术栈**: 取决于选择的OCR方案。
    *   **方案A (集成MarkItDown)**: 如果MarkItDown提供本地库或API，则直接集成。
    *   **方案B (云服务封装)**: Python + FastAPI，封装对第三方云OCR服务（如阿里云、腾讯云、Google Vision API）的调用。
*   **主要职责**:
    *   接收核心业务API服务传递的文件（或文件路径/URL）。
    *   调用OCR引擎处理图像或PDF文件，提取文本内容。
    *   对OCR结果进行必要的后处理（如版面分析、去除噪点、结构化提取，MVP阶段可简化）。
    *   将提取的文本内容返回给核心业务API服务。
*   **设计考虑**: 
    *   OCR处理可能是耗时操作，适合通过任务队列异步处理。
    *   处理多种文件格式 (PDF, JPG, PNG)。
    *   错误处理和识别准确率的监控。

### 3.5 任务队列 (Task Queue - MVP初期可选同步)
*   **技术栈**: Celery, Redis (作为Broker和Result Backend) 或 RabbitMQ。
*   **主要职责**:
    *   处理耗时操作，如OCR识别、复杂的AI内容生成，避免阻塞核心API服务的请求处理线程。
    *   提供任务状态跟踪机制。
*   **集成**: 核心业务API服务作为生产者发布任务，OCR服务和AI服务接口（或其一部分逻辑）作为消费者执行任务。
*   **MVP简化**: 初期如果并发量不高，可以将OCR和AI生成作为核心业务API服务中的同步阻塞调用，待性能瓶颈出现时再引入任务队列进行异步化改造。

### 3.6 数据库 (Database)
*   **技术选型**: PostgreSQL。
*   **主要职责**: 持久化存储应用数据，包括：
    *   用户信息 (User)。
    *   上传文件元数据 (UploadedFile)，包括文件名、存储路径、OCR状态、OCR结果文本（或其摘要/索引）。
    *   报告草稿 (ReportDraft)，包括标题、险种、各章节内容 (JSON格式)、创建和更新时间等。
*   **设计考虑**: 详细的数据模型见 `database_schema.md`。

### 3.7 对象存储 (Object Storage)
*   **技术选型**: MinIO (自建) 或云服务商对象存储 (如AWS S3, 阿里云OSS)。
*   **主要职责**: 存储用户上传的原始文件 (PDF, 图片等)。
*   **设计考虑**: 
    *   文件访问权限管理。
    *   存储成本和可扩展性。

## 4. 技术选型理由

*   **前端 (React + Next.js)**: 
    *   React拥有庞大的社区和丰富的生态系统。
    *   Next.js提供服务端渲染 (SSR)、静态站点生成 (SSG)、API路由等功能，简化开发，利于SEO和首屏加载性能。
*   **后端 (Python + FastAPI)**: 
    *   Python在AI/ML领域有强大的生态支持，便于集成LLM和OCR相关库。
    *   FastAPI基于Starlette和Pydantic，性能高，异步支持良好，代码简洁，自动生成API文档，开发效率高。
*   **富文本编辑器 (TipTap)**: 
    *   基于ProseMirror，无头(headless)设计，高度可定制，社区活跃，满足MVP的基础编辑需求。
*   **数据库 (PostgreSQL)**: 
    *   功能强大、稳定可靠的开源关系型数据库，支持JSONB等高级数据类型，适合存储结构化和半结构化数据。
*   **任务队列 (Celery + Redis)**: 
    *   Celery是Python中成熟的分布式任务队列，Redis作为Broker和Result Backend性能优异且易于部署。
*   **对象存储 (MinIO/S3)**: 
    *   提供标准化的S3兼容接口，无论是自建还是使用云服务，都具有良好的可移植性和扩展性。
*   **OCR服务**: 
    *   优先考虑成熟的云服务或高质量的开源方案，以保证识别准确率和处理效率。`MarkItDown` 若能满足需求且易于集成，也是一个选项。
*   **AI服务接口 (LLM)**: 
    *   选择具有强大文本生成能力、支持中文、API稳定且成本可控的LLM服务商。

## 5. 交互流程示例 (AI辅助章节生成)

1.  用户在前端界面选择要AI辅助生成的章节（如“事故经过”），并确保相关资料已上传且OCR完成。
2.  前端将请求（包含报告ID、章节标识、必要的上下文信息如关联的文件ID列表）发送到核心业务API服务。
3.  核心业务API服务根据报告ID和文件ID列表，从数据库或OCR结果缓存中获取相关的OCR文本内容。
4.  核心业务API服务组装该章节特定的提示词和上下文数据，调用AI服务接口。
5.  AI服务接口调用LLM API进行文本生成。
6.  LLM返回生成的文本给AI服务接口。
7.  AI服务接口将结果返回给核心业务API服务。
8.  核心业务API服务将生成的章节内容更新到报告草稿的对应章节，并返回给前端。
9.  前端在TipTap编辑器中显示AI生成的章节内容，用户可进行修改。

## 6. 安全考虑 (MVP)

*   **通信安全**: 所有外部通信使用HTTPS加密。
*   **身份认证与授权**: 
    *   用户登录采用安全的密码哈希存储 (如bcrypt)。
    *   API接口使用Token认证 (如JWT)，确保只有授权用户才能访问其数据。
*   **数据安全**: 
    *   对敏感数据（如用户个人信息、报告内容）在存储和传输时进行适当保护。
    *   防止SQL注入、XSS等常见Web攻击 (FastAPI等现代框架有一定内置防护)。
*   **依赖管理**: 定期更新第三方库，避免已知漏洞。
*   **OCR与AI服务**: 
    *   如果调用外部API，确保API密钥的安全管理。
    *   注意数据隐私，避免将敏感信息发送给不可信的第三方服务（除非用户明确同意且服务商有合规保障）。

## 7. 扩展性与可维护性

*   **模块化设计**: 各组件职责清晰，低耦合，便于独立开发、测试、部署和扩展。
*   **API驱动**: 服务间通过定义良好的API进行通信。
*   **配置化**: 将可变配置（如数据库连接、API密钥、提示词模板）外部化，方便不同环境部署和修改。
*   **代码规范与文档**: 遵循统一的编码规范，编写必要的代码注释和设计文档。
*   **日志与监控**: 完善的日志记录有助于问题排查和系统监控（MVP阶段可简化）。

## 8. 性能考虑 (MVP)

*   **异步处理**: 对于OCR、AI生成等耗时操作，长远考虑使用任务队列异步化。
*   **数据库优化**: 合理设计索引，优化慢查询。
*   **API性能**: FastAPI本身性能较高，注意避免在请求处理中执行过多阻塞操作。
*   **前端性能**: Next.js的SSR/SSG有助于提升首屏加载速度，注意代码分割和资源优化。

本文档后续会根据项目进展和技术选型细化进行更新。
